{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 \n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import Tensor\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICEs\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "df = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train\n",
    "- test\n",
    "- dataset(train_X, train_y)\n",
    "- dataloader(dataset, batch_size=batch, shuffle=True, drop_last=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 세팅\n",
    "CFG = {\n",
    "    'EPOCHS':100,\n",
    "    'LEARNING_RATE':0.001,\n",
    "    'BATCH_SIZE':256,\n",
    "    'SEED':41\n",
    "}\n",
    "\n",
    "# 랜덤 시드\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Validation Split\n",
    "train, val, _, _ = train_test_split(df, df['label'], test_size=0.2, random_state=CFG['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 문장(Text) 벡터화 -> TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df = 4, analyzer = 'word', ngram_range=(1, 2))\n",
    "vectorizer.fit(np.array(train[\"문장\"]))\n",
    "\n",
    "train_vec = vectorizer.transform(train[\"문장\"])\n",
    "val_vec = vectorizer.transform(val[\"문장\"])\n",
    "test_vec = vectorizer.transform(test[\"문장\"])\n",
    "\n",
    "print(train_vec.shape, val_vec.shape, test_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Label Encoding (유형, 극성, 시제, 확실성)\n",
    "type_le = preprocessing.LabelEncoder()\n",
    "train[\"유형\"] = type_le.fit_transform(train[\"유형\"].values)\n",
    "val[\"유형\"] = type_le.transform(val[\"유형\"].values)\n",
    "\n",
    "polarity_le = preprocessing.LabelEncoder()\n",
    "train[\"극성\"] = polarity_le.fit_transform(train[\"극성\"].values)\n",
    "val[\"극성\"] = polarity_le.transform(val[\"극성\"].values)\n",
    "\n",
    "tense_le = preprocessing.LabelEncoder()\n",
    "train[\"시제\"] = tense_le.fit_transform(train[\"시제\"].values)\n",
    "val[\"시제\"] = tense_le.transform(val[\"시제\"].values)\n",
    "\n",
    "certainty_le = preprocessing.LabelEncoder()\n",
    "train[\"확실성\"] = certainty_le.fit_transform(train[\"확실성\"].values)\n",
    "val[\"확실성\"] = certainty_le.transform(val[\"확실성\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_type = train[\"유형\"].values # sentence type\n",
    "train_polarity = train[\"극성\"].values # sentence polarity\n",
    "train_tense = train[\"시제\"].values # sentence tense\n",
    "train_certainty = train[\"확실성\"].values # sentence certainty\n",
    "\n",
    "train_labels = {\n",
    "    'type' : train_type,\n",
    "    'polarity' : train_polarity,\n",
    "    'tense' : train_tense,\n",
    "    'certainty' : train_certainty\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_type = val[\"유형\"].values # sentence type\n",
    "val_polarity = val[\"극성\"].values # sentence polarity\n",
    "val_tense = val[\"시제\"].values # sentence tense\n",
    "val_certainty = val[\"확실성\"].values # sentence certainty\n",
    "\n",
    "val_labels = {\n",
    "    'type' : val_type,\n",
    "    'polarity' : val_polarity,\n",
    "    'tense' : val_tense,\n",
    "    'certainty' : val_certainty\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, st_vec, st_labels):\n",
    "        self.st_vec = st_vec\n",
    "        self.st_labels = st_labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        st_vector = torch.FloatTensor(self.st_vec[index].toarray()).squeeze(0)\n",
    "        if self.st_labels is not None:\n",
    "            st_type = self.st_labels['type'][index]\n",
    "            st_polarity = self.st_labels['polarity'][index]\n",
    "            st_tense = self.st_labels['tense'][index]\n",
    "            st_certainty = self.st_labels['certainty'][index]\n",
    "            return st_vector, st_type, st_polarity, st_tense, st_certainty\n",
    "        else:\n",
    "            return st_vector\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.st_vec.toarray())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_vec, train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "\n",
    "val_dataset = CustomDataset(val_vec, val_labels)\n",
    "val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "input_dim = 9351\n",
    "data_dim = 9351\n",
    "hidden_dim = 200\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, seq_len, layers):\n",
    "        super(Model, self).__init__()\n",
    "        self.hidden_dim =hidden_dim\n",
    "        self.seq_len = seq_len\n",
    "        self.layers = layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers = layers, batch_first = True)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim, num_layers = layers, batch_first = True)\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.type_fc = nn.Linear(hidden_dim, 4, bias = True)\n",
    "        self.polarity_fc = nn.Linear(hidden_dim, 3, bias = True)\n",
    "        self.tense_fc = nn.Linear(hidden_dim, 3, bias = True)\n",
    "        self.certainty_fc = nn.Linear(hidden_dim, 2, bias = True)\n",
    "        #self.fc = nn.Linear(hidden_dim, output_dim, bias = True)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def reset_hidden_state(self, batch_size):\n",
    "        return (\n",
    "            torch.zeros(self.layers, batch_size, self.hidden_dim).to(device),\n",
    "            torch.zeros(self.layers, batch_size, self.hidden_dim).to(device)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(0)\n",
    "        #print(x.size())\n",
    "        hs = self.reset_hidden_state(1)\n",
    "        #print(f'hs[0]:{hs[0].shape}')\n",
    "        #print(f'hs[1]:{hs[1].shape}')\n",
    "        x, hs = self.lstm(x, hs)\n",
    "        x, hs = self.lstm2(x, hs)\n",
    "        x = self.drop(x) \n",
    "        #print(x.size())\n",
    "        x = x.reshape(-1, 200)\n",
    "        #print(x.size())\n",
    "        type_output = self.type_fc(x)\n",
    "        type_output = self.softmax(type_output)\n",
    "        polarity_output = self.polarity_fc(x)\n",
    "        polarity_output = self.softmax(polarity_output)\n",
    "        tense_output = self.tense_fc(x)\n",
    "        tense_output = self.softmax(tense_output)\n",
    "        certainty_output = self.certainty_fc(x)\n",
    "        certainty_output = self.softmax(certainty_output)\n",
    "        #x = self.fc(x[:-1])\n",
    "        #print(\"====\")\n",
    "        #print(type_output)\n",
    "        return type_output, polarity_output, tense_output, certainty_output #x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Current cuda device:', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    model.to(device)\n",
    "    \n",
    "    criterion = {\n",
    "        'type' : nn.CrossEntropyLoss().to(device),\n",
    "        'polarity' : nn.CrossEntropyLoss().to(device),\n",
    "        'tense' : nn.CrossEntropyLoss().to(device),\n",
    "        'certainty' : nn.CrossEntropyLoss().to(device)\n",
    "    }\n",
    "    \n",
    "    best_loss = 999999\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for sentence, type_label, polarity_label, tense_label, certainty_label in tqdm(iter(train_loader)):\n",
    "            sentence = sentence.to(device)\n",
    "            type_label = type_label.to(device)\n",
    "            polarity_label = polarity_label.to(device)\n",
    "            tense_label = tense_label.to(device)\n",
    "            certainty_label = certainty_label.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            type_logit, polarity_logit, tense_logit, certainty_logit = model(sentence)\n",
    "\n",
    "            loss = 0.25 * criterion['type'](type_logit, type_label) + \\\n",
    "                    0.25 * criterion['polarity'](polarity_logit, polarity_label) + \\\n",
    "                    0.25 * criterion['tense'](tense_logit, tense_label) + \\\n",
    "                    0.25 * criterion['certainty'](certainty_logit, certainty_label) \n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "        \n",
    "        val_loss, val_type_f1, val_polarity_f1, val_tense_f1, val_certainty_f1 = validation(model, val_loader, criterion, device)\n",
    "        print(f'Epoch : [{epoch}] Train Loss : [{np.mean(train_loss):.5f}] Val Loss : [{val_loss:.5f}] 유형 F1 : [{val_type_f1:.5f}] 극성 F1 : [{val_polarity_f1:.5f}] 시제 F1 : [{val_tense_f1:.5f}] 확실성 F1 : [{val_certainty_f1:.5f}]')\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "        if best_loss > val_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model = model\n",
    "            \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    \n",
    "    type_preds, polarity_preds, tense_preds, certainty_preds = [], [], [], []\n",
    "    type_labels, polarity_labels, tense_labels, certainty_labels = [], [], [], []\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sentence, type_label, polarity_label, tense_label, certainty_label in tqdm(iter(val_loader)):\n",
    "            sentence = sentence.to(device)\n",
    "            type_label = type_label.to(device)\n",
    "            polarity_label = polarity_label.to(device)\n",
    "            tense_label = tense_label.to(device)\n",
    "            certainty_label = certainty_label.to(device)\n",
    "            \n",
    "            type_logit, polarity_logit, tense_logit, certainty_logit = model(sentence)\n",
    "            \n",
    "            loss = 0.25 * criterion['type'](type_logit, type_label) + \\\n",
    "                    0.25 * criterion['polarity'](polarity_logit, polarity_label) + \\\n",
    "                    0.25 * criterion['tense'](tense_logit, tense_label) + \\\n",
    "                    0.25 * criterion['certainty'](certainty_logit, certainty_label)\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "            \n",
    "            type_preds += type_logit.argmax(1).detach().cpu().numpy().tolist()\n",
    "            type_labels += type_label.detach().cpu().numpy().tolist()\n",
    "            \n",
    "            polarity_preds += polarity_logit.argmax(1).detach().cpu().numpy().tolist()\n",
    "            polarity_labels += polarity_label.detach().cpu().numpy().tolist()\n",
    "            \n",
    "            tense_preds += tense_logit.argmax(1).detach().cpu().numpy().tolist()\n",
    "            tense_labels += tense_label.detach().cpu().numpy().tolist()\n",
    "            \n",
    "            certainty_preds += certainty_logit.argmax(1).detach().cpu().numpy().tolist()\n",
    "            certainty_labels += certainty_label.detach().cpu().numpy().tolist()\n",
    "    \n",
    "    type_f1 = f1_score(type_labels, type_preds, average='weighted')\n",
    "    polarity_f1 = f1_score(polarity_labels, polarity_preds, average='weighted')\n",
    "    tense_f1 = f1_score(tense_labels, tense_preds, average='weighted')\n",
    "    certainty_f1 = f1_score(certainty_labels, certainty_preds, average='weighted')\n",
    "    \n",
    "    return np.mean(val_loss), type_f1, polarity_f1, tense_f1, certainty_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "seq_length = 200\n",
    "\n",
    "model = Model(data_dim, hidden_dim, seq_length, 256).to(device)\n",
    "model.eval()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2,threshold_mode='abs',min_lr=1e-8, verbose=True)\n",
    "\n",
    "model = train(model, optimizer, train_loader, val_loader, scheduler, device)\n",
    "# 모델 학습\n",
    "#net = Model(data_dim, hidden_dim, seq_length, output_dim, 1).to(device)  \n",
    "#model, train_hist = train(net, train_loader, num_epochs = nb_epochs, lr = learning_rate, verbose = 20, patience = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test_vec, None)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    type_preds, polarity_preds, tense_preds, certainty_preds = [], [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sentence in tqdm(test_loader):\n",
    "            sentence = sentence.to(device)\n",
    "            \n",
    "            type_logit, polarity_logit, tense_logit, certainty_logit = model(sentence)\n",
    "            \n",
    "            type_preds += type_logit.argmax(1).detach().cpu().numpy().tolist()\n",
    "            polarity_preds += polarity_logit.argmax(1).detach().cpu().numpy().tolist()\n",
    "            tense_preds += tense_logit.argmax(1).detach().cpu().numpy().tolist()\n",
    "            certainty_preds += certainty_logit.argmax(1).detach().cpu().numpy().tolist()\n",
    "            \n",
    "    return type_preds, polarity_preds, tense_preds, certainty_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_preds, polarity_preds, tense_preds, certainty_preds = inference(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_preds = type_le.inverse_transform(type_preds)\n",
    "polarity_preds = polarity_le.inverse_transform(polarity_preds)\n",
    "tense_preds = tense_le.inverse_transform(tense_preds)\n",
    "certainty_preds = certainty_le.inverse_transform(certainty_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for type_pred, polarity_pred, tense_pred, certainty_pred in zip(type_preds, polarity_preds, tense_preds, certainty_preds):\n",
    "    predictions.append(type_pred+'-'+polarity_pred+'-'+tense_pred+'-'+certainty_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "submit['label'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./baseline_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stargan-v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13 |Anaconda, Inc.| (default, Jun  4 2021, 14:25:59) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "56ac9e226391ff4b9bb97a7266f7de8aac6a0147f12072446547a44f5facdf49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
