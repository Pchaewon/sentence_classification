{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kobert import get_tokenizer\n",
    "from kobert import get_pytorch_kobert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda:3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'SEED':41\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting parameters\n",
    "max_len = 90\n",
    "batch_size = 8\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 100\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate =  5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /data1/hom1/ict18/sentence/KoBERT/.cache/kobert_v1.zip\n",
      "using cached model. /data1/hom1/ict18/sentence/KoBERT/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "bertmodel, vocab = get_pytorch_kobert_model(cachedir=\".cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /data1/hom1/ict18/sentence/KoBERT/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        if label_idx==None:\n",
    "            self.labels=None\n",
    "        else:\n",
    "            self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "        \n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=2,\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        else:\n",
    "            out = pooler\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, _, _ = train_test_split(df, df['label'], test_size=0.2, random_state=CFG['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_le = preprocessing.LabelEncoder()\n",
    "train[\"유형\"] = type_le.fit_transform(train[\"유형\"].values)\n",
    "val[\"유형\"] = type_le.transform(val[\"유형\"].values)\n",
    "\n",
    "polarity_le = preprocessing.LabelEncoder()\n",
    "train[\"극성\"] = polarity_le.fit_transform(train[\"극성\"].values)\n",
    "val[\"극성\"] = polarity_le.transform(val[\"극성\"].values)\n",
    "\n",
    "tense_le = preprocessing.LabelEncoder()\n",
    "train[\"시제\"] = tense_le.fit_transform(train[\"시제\"].values)\n",
    "val[\"시제\"] = tense_le.transform(val[\"시제\"].values)\n",
    "\n",
    "certainty_le = preprocessing.LabelEncoder()\n",
    "train[\"확실성\"] = certainty_le.fit_transform(train[\"확실성\"].values)\n",
    "val[\"확실성\"] = certainty_le.transform(val[\"확실성\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_train=pd.concat([train['문장'],train['유형']],axis=1)\n",
    "polarity_train=pd.concat([train['문장'],train['극성']],axis=1)\n",
    "tense_train=pd.concat([train['문장'],train['시제']],axis=1)\n",
    "certainty_train=pd.concat([train['문장'],train['확실성']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_val=pd.concat([val['문장'],val['유형']],axis=1)\n",
    "polarity_val=pd.concat([val['문장'],val['극성']],axis=1)\n",
    "tense_val=pd.concat([val['문장'],val['시제']],axis=1)\n",
    "certainty_val=pd.concat([val['문장'],val['확실성']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_train_set_data = [[i, str(j)] for i, j in zip(type_train['문장'], type_train['유형'])]\n",
    "polarity_train_set_data = [[i, str(j)] for i, j in zip(polarity_train['문장'], polarity_train['극성'])]\n",
    "tense_train_set_data = [[i, str(j)] for i, j in zip(tense_train['문장'], tense_train['시제'])]\n",
    "certainty_train_set_data = [[i, str(j)] for i, j in zip(certainty_train['문장'], certainty_train['확실성'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_val_set_data = [[i, str(j)] for i, j in zip(type_val['문장'], type_val['유형'])]\n",
    "polarity_val_set_data = [[i, str(j)] for i, j in zip(polarity_val['문장'], polarity_val['극성'])]\n",
    "tense_val_set_data = [[i, str(j)] for i, j in zip(tense_val['문장'], tense_val['시제'])]\n",
    "certainty_val_set_data = [[i, str(j)] for i, j in zip(certainty_val['문장'], certainty_val['확실성'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=[[i,str(j)] for i,j in zip(test['문장'], np.zeros(7090,dtype=np.int64))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_train_set_data=BERTDataset(type_train_set_data,0,1,tok,max_len,True,False)\n",
    "polarity_train_set_data=BERTDataset(polarity_train_set_data,0,1,tok,max_len,True,False)\n",
    "tense_train_set_data=BERTDataset(tense_train_set_data,0,1,tok,max_len,True,False)\n",
    "certainty_train_set_data=BERTDataset(certainty_train_set_data,0,1,tok,max_len,True,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_val_set_data=BERTDataset(type_val_set_data,0,1,tok,max_len,True,False)\n",
    "polarity_val_set_data=BERTDataset(polarity_val_set_data,0,1,tok,max_len,True,False)\n",
    "tense_val_set_data=BERTDataset(tense_val_set_data,0,1,tok,max_len,True,False)\n",
    "certainty_val_set_data=BERTDataset(certainty_val_set_data,0,1,tok,max_len,True,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset=BERTDataset(test_data,0,1,tok,max_len,True,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_train_dataloader = torch.utils.data.DataLoader(type_train_set_data, batch_size=batch_size, num_workers=5)\n",
    "polarity_train_dataloader = torch.utils.data.DataLoader(polarity_train_set_data, batch_size=batch_size, num_workers=5)\n",
    "tense_train_dataloader = torch.utils.data.DataLoader(tense_train_set_data, batch_size=batch_size, num_workers=5)\n",
    "certainty_train_dataloader = torch.utils.data.DataLoader(certainty_train_set_data, batch_size=batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_val_dataloader = torch.utils.data.DataLoader(type_val_set_data, batch_size=batch_size, num_workers=5)\n",
    "polarity_val_dataloader = torch.utils.data.DataLoader(polarity_val_set_data, batch_size=batch_size, num_workers=5)\n",
    "tense_val_dataloader = torch.utils.data.DataLoader(tense_val_set_data, batch_size=batch_size, num_workers=5)\n",
    "certainty_val_dataloader = torch.utils.data.DataLoader(certainty_val_set_data, batch_size=batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader=torch.utils.data.DataLoader(test_dataset,batch_size=256,num_workers=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_model=BERTClassifier(bertmodel,num_classes=4, dr_rate=0.5)\n",
    "polarity_model=BERTClassifier(bertmodel,num_classes=3, dr_rate=0.5)\n",
    "tense_model=BERTClassifier(bertmodel,num_classes=3, dr_rate=0.5)\n",
    "certainty_model=BERTClassifier(bertmodel,num_classes=2, dr_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "type_optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in type_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in type_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "polarity_optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in polarity_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in polarity_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "tense_optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in tense_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in tense_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "certainty_optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in certainty_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in certainty_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nSamples=[575,13558,257,2151]\n",
    "normedWeights = [1 - (x / sum(nSamples)) for x in nSamples]\n",
    "normedWeights = torch.FloatTensor(normedWeights).to(device)\n",
    "type_loss = nn.CrossEntropyLoss(normedWeights)\n",
    "\n",
    "nSamples=[15793,183,565]\n",
    "normedWeights = [1 - (x / sum(nSamples)) for x in nSamples]\n",
    "normedWeights = torch.FloatTensor(normedWeights).to(device)\n",
    "polarity_loss = nn.CrossEntropyLoss(normedWeights)\n",
    "\n",
    "nSamples=[8032,1643,6866]\n",
    "normedWeights = [1 - (x / sum(nSamples)) for x in nSamples]\n",
    "normedWeights = torch.FloatTensor(normedWeights).to(device)\n",
    "tense_loss = nn.CrossEntropyLoss(normedWeights)\n",
    "\n",
    "nSamples=[15192,1349]\n",
    "normedWeights = [1 - (x / sum(nSamples)) for x in nSamples]\n",
    "normedWeights = torch.FloatTensor(normedWeights).to(device)\n",
    "certainty_loss = nn.CrossEntropyLoss(normedWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_optimizer = AdamW(type_optimizer_grouped_parameters, lr=learning_rate)\n",
    "polarity_optimizer = AdamW(polarity_optimizer_grouped_parameters, lr=learning_rate)\n",
    "tense_optimizer = AdamW(tense_optimizer_grouped_parameters, lr=learning_rate)\n",
    "certainty_optimizer = AdamW(certainty_optimizer_grouped_parameters, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_total = len(type_train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_scheduler = get_cosine_schedule_with_warmup(type_optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
    "polarity_scheduler = get_cosine_schedule_with_warmup(polarity_optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
    "tense_scheduler = get_cosine_schedule_with_warmup(tense_optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
    "certainty_scheduler = get_cosine_schedule_with_warmup(certainty_optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, val_loader, loss_function):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    \n",
    "    preds = []\n",
    "    labels = []\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(val_loader), total=len(val_loader)):\n",
    "            token_ids = token_ids.long().to(device)\n",
    "            segment_ids = segment_ids.long().to(device)\n",
    "            valid_length= valid_length\n",
    "            label = label.long().to(device)\n",
    "            out = model(token_ids, valid_length, segment_ids)\n",
    "            loss = loss_function(out, label)\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "            \n",
    "            preds += out.argmax(1).detach().cpu().numpy().tolist()\n",
    "            labels += label.detach().cpu().numpy().tolist()\n",
    "    \n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "\n",
    "    \n",
    "    return np.mean(val_loss), f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, optimizer, scheduler, val_loader, name, loss_function):\n",
    "    best_loss = 999999\n",
    "    best_model = None\n",
    "    early_stopping_threshold_count =0\n",
    "    for e in range(num_epochs):\n",
    "        train_acc = 0.0\n",
    "        test_acc = 0.0\n",
    "        model.train()\n",
    "        train_loss=[]\n",
    "        for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "            optimizer.zero_grad()\n",
    "            token_ids = token_ids.long().to(device)\n",
    "            segment_ids = segment_ids.long().to(device)\n",
    "            valid_length= valid_length\n",
    "            label = label.long().to(device)\n",
    "            out = model(token_ids, valid_length, segment_ids)\n",
    "            loss = loss_function(out, label)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "            scheduler.step()  # Update learning rate schedule\n",
    "            train_acc += calc_accuracy(out, label)\n",
    "            if batch_id % log_interval == 0:\n",
    "                print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "            train_loss.append(loss.item())\n",
    "            \n",
    "        print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "        \n",
    "        val_loss, f1=validation(model, val_loader, loss_function)\n",
    "        print(f'Epoch : [{e}] Train Loss : [{np.mean(train_loss):.5f}] Val Loss : [{val_loss:.5f}]  F1 : [{f1:.5f}]')\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "        if best_loss > val_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model = model\n",
    "            early_stopping_threshold_count =0\n",
    "        else:\n",
    "            early_stopping_threshold_count +=1\n",
    "        if early_stopping_threshold_count >=3:\n",
    "            print('Early stopping')\n",
    "            break\n",
    "        \n",
    "            \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0144d40502c5400296a00f92c3ad0e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1654 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 1.2257969379425049 train acc 0.5\n",
      "epoch 1 batch id 201 loss 1.1433652639389038 train acc 0.5541044776119403\n",
      "epoch 1 batch id 401 loss 1.3089152574539185 train acc 0.6197007481296758\n",
      "epoch 1 batch id 601 loss 0.723433256149292 train acc 0.6582778702163061\n",
      "epoch 1 batch id 801 loss 0.8412370085716248 train acc 0.6924157303370787\n",
      "epoch 1 batch id 1001 loss 0.6535593867301941 train acc 0.7144105894105894\n",
      "epoch 1 batch id 1201 loss 1.8856397867202759 train acc 0.732098251457119\n",
      "epoch 1 batch id 1401 loss 0.6375046372413635 train acc 0.7486616702355461\n",
      "epoch 1 batch id 1601 loss 1.2529233694076538 train acc 0.7597595252966896\n",
      "epoch 1 train acc 0.7623941958887546\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8874438ba54447696ec47c9609aebf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/414 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [0] Train Loss : [0.99896] Val Loss : [0.63646]  F1 : [0.86184]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38de11468dc4479a9fcea409ac63e283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1654 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 0.3805767893791199 train acc 1.0\n",
      "epoch 2 batch id 201 loss 0.2651229798793793 train acc 0.8600746268656716\n",
      "epoch 2 batch id 401 loss 0.40428605675697327 train acc 0.8712593516209476\n",
      "epoch 2 batch id 601 loss 0.480182409286499 train acc 0.8695923460898503\n",
      "epoch 2 batch id 801 loss 0.3990096151828766 train acc 0.8748439450686641\n",
      "epoch 2 batch id 1001 loss 0.08762066066265106 train acc 0.874000999000999\n",
      "epoch 2 batch id 1201 loss 1.8608652353286743 train acc 0.8751040799333888\n",
      "epoch 2 batch id 1401 loss 0.30836984515190125 train acc 0.8785688793718772\n",
      "epoch 2 batch id 1601 loss 0.3605375289916992 train acc 0.8804653341661461\n",
      "epoch 2 train acc 0.8804413542926239\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec67590b6538417a9535ebe051ad60b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/414 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1] Train Loss : [0.58451] Val Loss : [0.64192]  F1 : [0.88207]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d4e3f0a0c1464b9549da00ad325dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1654 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1 loss 0.14632119238376617 train acc 0.875\n",
      "epoch 3 batch id 201 loss 0.06814781576395035 train acc 0.8793532338308457\n",
      "epoch 3 batch id 401 loss 0.13821561634540558 train acc 0.8946384039900249\n",
      "epoch 3 batch id 601 loss 0.5329660773277283 train acc 0.894134775374376\n",
      "epoch 3 batch id 801 loss 0.06609110534191132 train acc 0.8979400749063671\n",
      "epoch 3 batch id 1001 loss 0.026273634284734726 train acc 0.8952297702297702\n",
      "epoch 3 batch id 1201 loss 1.4183930158615112 train acc 0.8963363863447127\n",
      "epoch 3 batch id 1401 loss 0.027169886976480484 train acc 0.8993576017130621\n",
      "epoch 3 batch id 1601 loss 0.07900922000408173 train acc 0.9022485946283573\n",
      "epoch 3 train acc 0.9028869407496977\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad4e3805f3e48e5aed1aabc0b44d761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/414 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2] Train Loss : [0.52354] Val Loss : [0.79107]  F1 : [0.88105]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "744be7aedd83460283ee5890a19079e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1654 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 1 loss 0.23291684687137604 train acc 0.875\n",
      "epoch 4 batch id 201 loss 0.020428139716386795 train acc 0.8812189054726368\n",
      "epoch 4 batch id 401 loss 0.11047447472810745 train acc 0.8937032418952618\n",
      "epoch 4 batch id 601 loss 0.5946571230888367 train acc 0.896630615640599\n",
      "epoch 4 batch id 801 loss 0.049391236156225204 train acc 0.9024656679151061\n",
      "epoch 4 batch id 1001 loss 0.011167455464601517 train acc 0.9032217782217782\n",
      "epoch 4 batch id 1201 loss 1.934476375579834 train acc 0.9058076602830974\n",
      "epoch 4 batch id 1401 loss 0.009304380044341087 train acc 0.9095289079229122\n",
      "epoch 4 batch id 1601 loss 0.048136308789253235 train acc 0.9134915677701436\n",
      "epoch 4 train acc 0.9143742442563483\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "debc28a72e1a4bae85b71934f0353ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/414 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3] Train Loss : [0.50532] Val Loss : [0.90853]  F1 : [0.88345]\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "type_model=train(type_model,type_train_dataloader, type_optimizer, type_scheduler, type_val_dataloader, 'type', type_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70063c06a2594d1598978257dcba8e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1654 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 1.441328525543213 train acc 0.0\n",
      "epoch 1 batch id 201 loss 1.347513198852539 train acc 0.12686567164179105\n",
      "epoch 1 batch id 401 loss 0.4696314334869385 train acc 0.3974438902743142\n",
      "epoch 1 batch id 601 loss 2.155280590057373 train acc 0.5846505823627288\n",
      "epoch 1 batch id 801 loss 0.07204989343881607 train acc 0.6771223470661673\n",
      "epoch 1 batch id 1001 loss 0.038335464894771576 train acc 0.7321428571428571\n",
      "epoch 1 batch id 1201 loss 0.032422080636024475 train acc 0.7693588676103247\n",
      "epoch 1 batch id 1401 loss 0.02649766393005848 train acc 0.7957708779443254\n",
      "epoch 1 batch id 1601 loss 1.2515182495117188 train acc 0.8148813241723922\n",
      "epoch 1 train acc 0.8195284159613059\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491f5974839a413e980f18f779eb59a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/414 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [0] Train Loss : [0.94687] Val Loss : [0.60394]  F1 : [0.93030]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5da26ed8fa46d0adfb8929b843c41b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1654 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 0.020177537575364113 train acc 1.0\n",
      "epoch 2 batch id 201 loss 0.017890745773911476 train acc 0.9589552238805971\n",
      "epoch 2 batch id 401 loss 0.012472732923924923 train acc 0.9597880299251871\n",
      "epoch 2 batch id 601 loss 3.439194679260254 train acc 0.9636023294509152\n",
      "epoch 2 batch id 801 loss 0.010147104039788246 train acc 0.9656679151061174\n",
      "epoch 2 batch id 1001 loss 0.006915493868291378 train acc 0.9665334665334665\n",
      "epoch 2 batch id 1201 loss 0.008684694766998291 train acc 0.9677352206494588\n",
      "epoch 2 batch id 1401 loss 0.007105417549610138 train acc 0.9681477516059958\n",
      "epoch 2 batch id 1601 loss 0.023674221709370613 train acc 0.9681449094316052\n",
      "epoch 2 train acc 0.968409915356711\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dabcc79afaed46d1889b03a3bf87b56b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/414 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1] Train Loss : [0.52425] Val Loss : [0.35139]  F1 : [0.96273]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a8c4b5e0b24345837e3509011f2b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1654 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1 loss 0.009783676825463772 train acc 1.0\n",
      "epoch 3 batch id 201 loss 0.007711075711995363 train acc 0.9701492537313433\n",
      "epoch 3 batch id 401 loss 0.006249956786632538 train acc 0.9741271820448878\n",
      "epoch 3 batch id 601 loss 3.469383955001831 train acc 0.9762895174708819\n",
      "epoch 3 batch id 801 loss 0.005902361590415239 train acc 0.9753433208489388\n",
      "epoch 3 batch id 1001 loss 0.005322685930877924 train acc 0.9756493506493507\n",
      "epoch 3 batch id 1201 loss 0.004161996766924858 train acc 0.9760616153205662\n",
      "epoch 3 batch id 1401 loss 0.003681275760754943 train acc 0.9766238401142041\n",
      "epoch 3 batch id 1601 loss 0.014508719556033611 train acc 0.9761086820737039\n",
      "epoch 3 train acc 0.9761940749697703\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15c7b59f7e64ca48b6df9a17e654ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/414 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2] Train Loss : [0.39006] Val Loss : [0.39568]  F1 : [0.97067]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b4afa57ef147289058414732572f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1654 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 1 loss 0.0032567407470196486 train acc 1.0\n",
      "epoch 4 batch id 201 loss 0.0036923233419656754 train acc 0.9776119402985075\n",
      "epoch 4 batch id 401 loss 0.002738969400525093 train acc 0.9778678304239401\n",
      "epoch 4 batch id 601 loss 0.010881985537707806 train acc 0.9796173044925125\n",
      "epoch 4 batch id 801 loss 0.0029488462023437023 train acc 0.9783083645443196\n",
      "epoch 4 batch id 1001 loss 0.0034035800490528345 train acc 0.9787712287712288\n",
      "epoch 4 batch id 1201 loss 0.0025848536752164364 train acc 0.9791840133222315\n",
      "epoch 4 batch id 1401 loss 0.002130878157913685 train acc 0.9799250535331906\n",
      "epoch 4 batch id 1601 loss 0.00908734556287527 train acc 0.9795440349781387\n",
      "epoch 4 train acc 0.9798216444981862\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbd0bcef132744948fabe6af0b13e63f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/414 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3] Train Loss : [0.35587] Val Loss : [0.40648]  F1 : [0.97191]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9248c6dfc18459d99885839fe21898b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1654 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 1 loss 0.0023647139314562082 train acc 1.0\n",
      "epoch 5 batch id 201 loss 0.003007124410942197 train acc 0.9782338308457711\n",
      "epoch 5 batch id 401 loss 0.001827083877287805 train acc 0.9788029925187033\n",
      "epoch 5 batch id 601 loss 0.007006478030234575 train acc 0.9810732113144759\n",
      "epoch 5 batch id 801 loss 0.0019518944900482893 train acc 0.9804931335830213\n",
      "epoch 5 batch id 1001 loss 0.0019228343153372407 train acc 0.9812687312687313\n",
      "epoch 5 batch id 1201 loss 0.001923520932905376 train acc 0.9813696919233972\n",
      "epoch 5 batch id 1401 loss 0.0016129453433677554 train acc 0.981887937187723\n",
      "epoch 5 batch id 1601 loss 0.012760600075125694 train acc 0.9817301686445972\n",
      "epoch 5 train acc 0.9819377267230955\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1390961f68e24104841be463ba5f16c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/414 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4] Train Loss : [0.31870] Val Loss : [0.42671]  F1 : [0.96911]\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "polarity_model=train(polarity_model, polarity_train_dataloader,polarity_optimizer, polarity_scheduler, polarity_val_dataloader, 'polarity', polarity_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924a0d4c4da6437eba954f94f2854fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1654 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 1.1805119514465332 train acc 0.375\n",
      "epoch 1 batch id 201 loss 1.0521631240844727 train acc 0.26927860696517414\n",
      "epoch 1 batch id 401 loss 0.9507574439048767 train acc 0.3444513715710723\n",
      "epoch 1 batch id 601 loss 0.7635687589645386 train acc 0.43718801996672213\n",
      "epoch 1 batch id 801 loss 0.2700583338737488 train acc 0.5332397003745318\n",
      "epoch 1 batch id 1001 loss 0.28905290365219116 train acc 0.6013986013986014\n",
      "epoch 1 batch id 1201 loss 0.4421083331108093 train acc 0.6472731057452124\n",
      "epoch 1 batch id 1401 loss 0.06933211535215378 train acc 0.6821020699500356\n",
      "epoch 1 batch id 1601 loss 0.04656066745519638 train acc 0.7065115552779513\n",
      "epoch 1 train acc 0.7116837968561064\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d3d65c37ea3423596247af5d4fee9ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/414 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [0] Train Loss : [0.67424] Val Loss : [0.41851]  F1 : [0.88580]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f108d070363347e5af7f9ed6b70f2f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1654 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 0.03835670277476311 train acc 1.0\n",
      "epoch 2 batch id 201 loss 0.362768292427063 train acc 0.8961442786069652\n",
      "epoch 2 batch id 401 loss 0.05786117538809776 train acc 0.898067331670823\n",
      "epoch 2 batch id 601 loss 0.57061767578125 train acc 0.8951747088186356\n",
      "epoch 2 batch id 801 loss 0.03298766538500786 train acc 0.892478152309613\n",
      "epoch 2 batch id 1001 loss 0.03130272403359413 train acc 0.8943556443556444\n",
      "epoch 2 batch id 1201 loss 0.6473284363746643 train acc 0.8959200666111574\n",
      "epoch 2 batch id 1401 loss 0.02183251641690731 train acc 0.8992683797287652\n",
      "epoch 2 batch id 1601 loss 0.01692136749625206 train acc 0.8989693941286696\n",
      "epoch 2 train acc 0.8981257557436517\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b09ee19eef0d4c278f60d6bc1d40bf86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/414 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1] Train Loss : [0.38552] Val Loss : [0.45083]  F1 : [0.88386]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94514020359a41e89f1997542ba029f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1654 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1 loss 0.023181436583399773 train acc 1.0\n",
      "epoch 3 batch id 201 loss 0.046251654624938965 train acc 0.8917910447761194\n",
      "epoch 3 batch id 401 loss 0.1596718579530716 train acc 0.8993142144638404\n",
      "epoch 3 batch id 601 loss 0.5957642197608948 train acc 0.9022462562396006\n",
      "epoch 3 batch id 801 loss 0.017972372472286224 train acc 0.9024656679151061\n",
      "epoch 3 batch id 1001 loss 0.025851937010884285 train acc 0.9040959040959041\n",
      "epoch 3 batch id 1201 loss 0.6422171592712402 train acc 0.9068484596169858\n",
      "epoch 3 batch id 1401 loss 0.01328431349247694 train acc 0.9105995717344754\n",
      "epoch 3 batch id 1601 loss 0.011883329600095749 train acc 0.9119300437226733\n",
      "epoch 3 train acc 0.9111245465538089\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a1ba4be42884359a669dd60e6ecd26f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/414 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2] Train Loss : [0.36615] Val Loss : [0.49204]  F1 : [0.89078]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e355295d1454d10ade920ce2bb59a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1654 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 1 loss 0.013363776728510857 train acc 1.0\n",
      "epoch 4 batch id 201 loss 0.10875698179006577 train acc 0.8930348258706468\n",
      "epoch 4 batch id 401 loss 0.29926949739456177 train acc 0.9014962593516209\n",
      "epoch 4 batch id 601 loss 0.6586987972259521 train acc 0.9043261231281198\n",
      "epoch 4 batch id 801 loss 0.013041781261563301 train acc 0.906210986267166\n",
      "epoch 4 batch id 1001 loss 0.02259519137442112 train acc 0.9094655344655345\n",
      "epoch 4 batch id 1201 loss 0.5588502883911133 train acc 0.9121565362198168\n",
      "epoch 4 batch id 1401 loss 0.009458492510020733 train acc 0.9167558886509636\n",
      "epoch 4 batch id 1601 loss 0.009776146151125431 train acc 0.9181761399125546\n",
      "epoch 4 train acc 0.9179262394195888\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f51762cd82240479e2021530599679b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/414 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3] Train Loss : [0.35521] Val Loss : [0.51664]  F1 : [0.88639]\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "tense_model=train(tense_model, tense_train_dataloader, tense_optimizer, tense_scheduler, tense_val_dataloader,'tense',tense_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04fe16cf0294a76ace7ffa6e4c0f166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1654 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 0.8062800168991089 train acc 0.25\n",
      "epoch 1 batch id 201 loss 0.38894277811050415 train acc 0.6075870646766169\n",
      "epoch 1 batch id 401 loss 0.07595953345298767 train acc 0.7593516209476309\n",
      "epoch 1 batch id 601 loss 0.06562653183937073 train acc 0.8132279534109818\n",
      "epoch 1 batch id 801 loss 0.017638487741351128 train acc 0.8408239700374532\n",
      "epoch 1 batch id 1001 loss 0.014156739227473736 train acc 0.8562687312687313\n",
      "epoch 1 batch id 1201 loss 0.03233494609594345 train acc 0.8672980849292257\n",
      "epoch 1 batch id 1401 loss 0.006194839719682932 train acc 0.8758029978586723\n",
      "epoch 1 batch id 1601 loss 0.03026076965034008 train acc 0.8801530293566521\n",
      "epoch 1 train acc 0.8811215235792019\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec7c0f9f4e44018b0f166a35a0dabad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/414 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [0] Train Loss : [0.14237] Val Loss : [0.03964]  F1 : [0.87274]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7a655d92664455961f9232c0582f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1654 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 0.02675476111471653 train acc 1.0\n",
      "epoch 2 batch id 201 loss 0.04759451374411583 train acc 0.927860696517413\n",
      "epoch 2 batch id 401 loss 0.006378155201673508 train acc 0.9205112219451371\n",
      "epoch 2 batch id 601 loss 0.04327165335416794 train acc 0.920549084858569\n",
      "epoch 2 batch id 801 loss 0.004766068886965513 train acc 0.9213483146067416\n",
      "epoch 2 batch id 1001 loss 0.01577947661280632 train acc 0.9208291708291708\n",
      "epoch 2 batch id 1201 loss 0.02201961539685726 train acc 0.9216278101582015\n",
      "epoch 2 batch id 1401 loss 0.002971262438222766 train acc 0.9231798715203426\n",
      "epoch 2 batch id 1601 loss 0.011543757282197475 train acc 0.9228607120549657\n",
      "epoch 2 train acc 0.9229141475211609\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68ccd33c73c4337829c701b5f61a414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/414 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1] Train Loss : [0.03890] Val Loss : [0.04248]  F1 : [0.91741]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d4a4be51cd2401d9317d4a6bdbfb300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1654 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1 loss 0.017034392803907394 train acc 1.0\n",
      "epoch 3 batch id 201 loss 0.06152062118053436 train acc 0.9365671641791045\n",
      "epoch 3 batch id 401 loss 0.006844318471848965 train acc 0.9317331670822943\n",
      "epoch 3 batch id 601 loss 0.018648996949195862 train acc 0.93261231281198\n",
      "epoch 3 batch id 801 loss 0.0023276268038898706 train acc 0.9355493133583022\n",
      "epoch 3 batch id 1001 loss 0.0033039499539881945 train acc 0.9348151848151848\n",
      "epoch 3 batch id 1201 loss 0.015329592861235142 train acc 0.9348459616985845\n",
      "epoch 3 batch id 1401 loss 0.0029074563644826412 train acc 0.9363847251962883\n",
      "epoch 3 batch id 1601 loss 0.004436803981661797 train acc 0.9368363522798251\n",
      "epoch 3 train acc 0.9371977025392987\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9123912700814c6f994dc218255b64a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/414 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2] Train Loss : [0.03805] Val Loss : [0.05039]  F1 : [0.91906]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18569ede7dbc4245a9c9c0d288c2d894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1654 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 1 loss 0.0024489383213222027 train acc 1.0\n",
      "epoch 4 batch id 201 loss 0.07271525263786316 train acc 0.9427860696517413\n",
      "epoch 4 batch id 401 loss 0.010010959580540657 train acc 0.9360972568578554\n",
      "epoch 4 batch id 601 loss 0.009100777097046375 train acc 0.9417637271214643\n",
      "epoch 4 batch id 801 loss 0.002240594709292054 train acc 0.9447565543071161\n",
      "epoch 4 batch id 1001 loss 0.00170193612575531 train acc 0.9448051948051948\n",
      "epoch 4 batch id 1201 loss 0.011457439512014389 train acc 0.9450457951706911\n",
      "epoch 4 batch id 1401 loss 0.0025608958676457405 train acc 0.9467344753747323\n",
      "epoch 4 batch id 1601 loss 0.004894557408988476 train acc 0.948001249219238\n",
      "epoch 4 train acc 0.9483071342200725\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca1981c5c98455ca53244e41b873065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/414 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3] Train Loss : [0.03637] Val Loss : [0.06081]  F1 : [0.92521]\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "certainty_model=train(certainty_model, certainty_train_dataloader, certainty_optimizer, certainty_scheduler, certainty_val_dataloader,'certainty', certainty_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    preds = []\n",
    "    \n",
    "    for batch_idx,(token_ids, valid_length, segment_ids,labels) in tqdm(enumerate(test_loader), total=len(test_dataloader)):\n",
    "        \n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        \n",
    "        preds += out.argmax(1).detach().cpu().numpy().tolist()\n",
    "        \n",
    "        \n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd1974db929f4c31980c9a0ca0efd6e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "type_preds = inference(type_model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b4d76c58ff046848d1725db665965a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "polarity_preds = inference(polarity_model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51906ebb36f840afa01448d8a551f0d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tense_preds = inference(tense_model, test_dataloader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd7d4ed36eb44e4e8b800b47b1dc7a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "certainty_preds = inference(certainty_model, test_dataloader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_preds = type_le.inverse_transform(type_preds)\n",
    "polarity_preds = polarity_le.inverse_transform(polarity_preds)\n",
    "tense_preds = tense_le.inverse_transform(tense_preds)\n",
    "certainty_preds = certainty_le.inverse_transform(certainty_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for type_pred, polarity_pred, tense_pred, certainty_pred in zip(type_preds, polarity_preds, tense_preds, certainty_preds):\n",
    "    predictions.append(type_pred+'-'+polarity_pred+'-'+tense_pred+'-'+certainty_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('data/sample_submission.csv')\n",
    "submit['label'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0001</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0002</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0004</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID         label\n",
       "0  TEST_0000  사실형-긍정-현재-확실\n",
       "1  TEST_0001  사실형-긍정-현재-확실\n",
       "2  TEST_0002  사실형-긍정-과거-확실\n",
       "3  TEST_0003  사실형-긍정-현재-확실\n",
       "4  TEST_0004  사실형-긍정-과거-확실"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./baseline_submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('sentence': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c4bfc0b13d112990dad16003f4e567da097a51e9a7859720d35367279d4aa03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
